============================================================
bi_min_lstm - Evaluation Metrics
============================================================

Overall Accuracy: 0.8886

Macro Averaged Metrics:
  Precision: 0.7957
  Recall: 0.7482
  F1-Score: 0.7666

Weighted Averaged Metrics:
  Precision: 0.8851
  Recall: 0.8886
  F1-Score: 0.8848

============================================================
Per-Class Metrics:
============================================================

None:
  Precision: 0.9177
  Recall: 0.9501
  F1-Score: 0.9336
  Support: 4509

Racist:
  Precision: 0.6861
  Recall: 0.7157
  F1-Score: 0.7006
  Support: 394

Sexist:
  Precision: 0.7831
  Recall: 0.5786
  F1-Score: 0.6655
  Support: 674

============================================================
Classification Report:
============================================================

              precision    recall  f1-score   support

        None       0.92      0.95      0.93      4509
      Racist       0.69      0.72      0.70       394
      Sexist       0.78      0.58      0.67       674

    accuracy                           0.89      5577
   macro avg       0.80      0.75      0.77      5577
weighted avg       0.89      0.89      0.88      5577
